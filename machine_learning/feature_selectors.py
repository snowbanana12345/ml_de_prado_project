from sklearn.ensemble import RandomForestClassifier
from machine_learning.base_model import PreProcessor
from machine_learning.feature_generators import FeatureGenerator
from machine_learning.filter_generators import FilterGenerator
from machine_learning.label_generators import LabelGenerator
from machine_learning.model_performance import binary_classification_metrics
import pandas as pd
import numpy as np
import copy
import time


class ClassificationMdi(PreProcessor):
    def __init__(self, feature_generator: FeatureGenerator, label_generator: LabelGenerator,
                 filter_generator: FilterGenerator, random_forest : RandomForestClassifier):
        super().__init__(feature_generator, label_generator, filter_generator)
        self.random_forest = random_forest
        self.models = [copy.deepcopy(self.random_forest) for _ in range(len(self.label_list))]

    def fit(self) -> None:
        """
        Fits a copy of the random forest to each label generated by the label generator
        :return: None
        """
        start_time = time.time()
        # ---- START -----
        train_df = self.processed_train_df[self.processed_train_df[self.filter_col_name]].dropna()
        train_features = train_df[self.feature_list]
        for label, model in zip(self.label_list, self.models):
            model.fit(train_features, train_df[label])
        # ---- END -----
        end_time = time.time()
        print("Finished fitting : elasped time : " + str(end_time - start_time))

    def get_mdi(self)->[pd.DataFrame]:
        """
        :return: A list of dataframes containing results for the random forest applied to predict each label
        """
        mdi_lst = []
        for model in self.models:
            mdi_lst.append(self.feat_impt_mdi(model))
        return mdi_lst

    def feat_impt_mdi(self, fit) -> pd.DataFrame:
        """
        Code taken from Advances in machine learning, Macros De Prado pg 116
        :return: DataFrame containing the mean importance and std of features
        in the format,
                     mean     std
        feature 1    ....     ....
        feature 2    ....     ....
        """
        # feat importance based on IS mean impurity reduction
        df0 = {i: tree.feature_importances_ for i, tree in enumerate(fit.estimators_)}
        df0 = pd.DataFrame.from_dict(df0, orient='index')
        df0.columns = self.feature_list
        df0 = df0.replace(0, np.nan)
        imp = pd.concat({'mean': df0.mean(), 'std': df0.std() * df0.shape[0] ** -.5}, axis=1)
        imp /= imp['mean'].sum()
        return imp

    def reset(self):
        super().reset()
        self.models = [copy.deepcopy(self.random_forest) for _ in range(len(self.label_list))]


class ClassificationMda(PreProcessor):
    def __init__(self, feature_generator: FeatureGenerator, label_generator: LabelGenerator,
                 filter_generator: FilterGenerator, base_model):
        super().__init__(feature_generator, label_generator, filter_generator)
        self.base_model = base_model
        self.models = [copy.deepcopy(self.base_model) for _ in range(len(self.label_list))]

    def fit(self) -> None:
        start_time = time.time()
        # ---- START -----
        train_df = self.processed_train_df[self.processed_train_df[self.filter_col_name]].dropna()
        train_features = train_df[self.feature_list]
        for label, model in zip(self.label_list, self.models):
            model.fit(train_features, train_df[label])
        # ---- END -----
        end_time = time.time()
        print("Finished fitting : elasped time : " + str(end_time - start_time))

    def get_mda(self) -> [dict]:
        test_df = self.processed_test_df[self.processed_test_df[self.filter_col_name]].dropna()
        test_features = test_df[self.feature_list]
        scrambled_test_features = test_features.copy(deep = True)
        results = {}
        for label, model in zip(self.label_list, self.models):
            label_result = {}
            target = test_df[label]
            prediction = model.predict(test_features) # get prediction performance for
            label_result["Unscrambled"] = binary_classification_metrics(target, prediction)
            for feature in self.feature_list:
                np.random.shuffle(scrambled_test_features[feature].values)
                prediction = model.predict(scrambled_test_features)
                label_result[feature] = (binary_classification_metrics(target, prediction))
                scrambled_test_features[feature] = test_features[feature]
            results[label] = label_result
        return results

    def reset(self):
        super().reset()
        self.models = [copy.deepcopy(self.base_model) for _ in range(len(self.label_list))]


class ClassificationMdaMdi(ClassificationMda):
    def __init__(self, feature_generator: FeatureGenerator, label_generator: LabelGenerator,
                 filter_generator: FilterGenerator, base_model : RandomForestClassifier):
        super().__init__(feature_generator, label_generator, filter_generator, base_model)


    def get_mdi(self)->dict:
        """
        :return: A list of dataframes containing results for the random forest applied to predict each label
        """
        mdi_lst = {}
        for label, model in zip(self.label_list, self.models):
            mdi_lst[label] = self.feat_impt_mdi(model)
        return mdi_lst

    def feat_impt_mdi(self, fit) -> pd.DataFrame:
        """
        Code taken from Advances in machine learning, Macros De Prado pg 116
        :return: DataFrame containing the mean importance and std of features
        in the format,
                     mean     std
        feature 1    ....     ....
        feature 2    ....     ....
        """
        # feat importance based on IS mean impurity reduction
        df0 = {i: tree.feature_importances_ for i, tree in enumerate(fit.estimators_)}
        df0 = pd.DataFrame.from_dict(df0, orient='index')
        df0.columns = self.feature_list
        df0 = df0.replace(0, np.nan)
        imp = pd.concat({'mean': df0.mean(), 'std': df0.std() * df0.shape[0] ** -.5}, axis=1)
        imp /= imp['mean'].sum()
        return imp
